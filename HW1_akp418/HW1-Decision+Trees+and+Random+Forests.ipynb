{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this homework you can get 100 points + 20 bonus points. The bonus points will be counted into your total homework score until you get the maximum homework score, 400.\n",
    "\n",
    "Copying and pasting other people's code is absolutely prohibited.  I will report to the education team if I find any such cases. Collaboration and discussion is highly encouraged, and feel free to exchange ideas with your classmates, but write your own code please. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 1: Accuracy and interpretability (10 pts)\n",
    "\n",
    "a) Describe a real-world prediction problem using urban data for which _interpretability_ of your models and results is essential, and for which it might be preferable to use decision trees rather than random forests.  Argue why this is the case. (3 pts)\n",
    "\n",
    "b) Describe a real-world prediction problem using urban data for which _accuracy_ is paramount and interpretability may be less important, and for which it might be preferable to use random forests rather than decision trees.  Argue why this is the case. (3 pts)\n",
    "\n",
    "c) Let's imagine that you want to try to get the best of both worlds (accuracy _and_ interpretability).  So you decide to start by learning a random forest classifier.  Describe at least one way of getting some interpretability out of the model by post-processing.  You could either pick a method from the literature (e.g., Domingos's work on combining multiple models or some method of computing variable importance), or come up with your own approach (doesn't have to be ground-breaking, but feel free to be creative!) (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 2: Build a tree by hand following exactly the lecture notes. Note that the dataset has been slightly modified, so you will get a different tree than the one shown in the lecture notes. (30 pts + 20 pts)\n",
    "\n",
    "30 points for parts a, b, c, d, f.\n",
    "20 bonus points for optional part e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data='MPG, cylinders, HP, weight\\ngood, 4, 75, light\\nbad, 6, 90, medium\\nbad, 4, 110, medium\\nbad, 8, 175, weighty\\nbad, 6, 95, medium\\nbad, 4, 94, light\\nbad, 4, 95, light\\nbad, 8, 139, weighty\\nbad, 8, 190, weighty\\nbad, 8, 145, weighty\\nbad, 6, 100, medium\\ngood, 4, 92, medium\\nbad, 6, 100, weighty\\nbad, 8, 170, weighty\\ngood, 4, 89, medium\\ngood, 4, 65, light\\nbad, 6, 85, medium\\ngood, 4, 81, light\\nbad, 6, 95, medium\\ngood, 4, 93, light'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPG,cylinders,HP,weight\n",
      "good,4,75,light\n",
      "bad,6,90,medium\n",
      "bad,4,110,medium\n",
      "bad,8,175,weighty\n",
      "bad,6,95,medium\n",
      "bad,4,94,light\n",
      "bad,4,95,light\n",
      "bad,8,139,weighty\n",
      "bad,8,190,weighty\n",
      "bad,8,145,weighty\n",
      "bad,6,100,medium\n",
      "good,4,92,medium\n",
      "bad,6,100,weighty\n",
      "bad,8,170,weighty\n",
      "good,4,89,medium\n",
      "good,4,65,light\n",
      "bad,6,85,medium\n",
      "good,4,81,light\n",
      "bad,6,95,medium\n",
      "good,4,93,light\n"
     ]
    }
   ],
   "source": [
    "data=\",\".join(data.split(\", \"))\n",
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please use numpy and pandas to do the calculation for parts a) through d):\n",
    "\n",
    "a) Prepare the data set to a pandas dataframe from the given string (2 pts)\n",
    "\n",
    "b) Start with the entire dataset and find the most common value (3 pts)\n",
    "\n",
    "c) Use \"information gain\" as your decision rule to split your data into two groups. What is the split rule and what is the maximum value of the information gain? (5 pts)\n",
    "\n",
    "d) Repeat the process b) and c) until that you can perfectly split the training data.  Show the resulting decision tree in a format of your choice, as long as the tree structure and the prediction at each leaf node are clearly shown.  Note that you are _not_ expected to prune the tree in parts d) and e). (10 pts)\n",
    "\n",
    "e)*OPTIONAL- 20 bonus points* \n",
    "Define a function: Tree(data_train, data_test) which learns a decision tree from data_train and uses it to predict the values for data_test.\n",
    "\n",
    "Example:\n",
    "\n",
    "##### Input of the desired function:\n",
    "\n",
    "data_train=\"good,4,75,light\\nbad,6,90,medium\\nbad,4,110,medium\"\n",
    "\n",
    "data_test=\"?,6,95,medium\\n?,4,93,light\"\n",
    "\n",
    "##### Output of the desired function should be data_test with the unknown values replaced by your tree's predictions, e.g.:\n",
    "\n",
    "data_test_predicted=\"bad,6,95,medium\\ngood,4,93,light\"\n",
    "\n",
    "f) Classify the following five vehicles as having \"good\" or \"bad\" fuel efficiency (miles per gallon).  You can do this by hand using the tree structure learned in part d), or automatically using the function you wrote in part e). (10 pts)\n",
    "\n",
    "?,4,93,weighty\n",
    "?,8,70,light\n",
    "?,6,113,medium\n",
    "?,6,95,weighty\n",
    "?,4,115,medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3, Predicting burden of disease （40 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the first three rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>FrxnPeaceIn10</th>\n",
       "      <th>ODA4H2OPcptaDol</th>\n",
       "      <th>RenewResm3PcptaYr</th>\n",
       "      <th>SustAccImprWatRur</th>\n",
       "      <th>SustAccImprWatUrb</th>\n",
       "      <th>SustAccImprSanRur</th>\n",
       "      <th>SustAccImprSanUrb</th>\n",
       "      <th>TotHlthExpPctofGDP</th>\n",
       "      <th>GenGovtPctofTotHlthExp</th>\n",
       "      <th>ExtResHlthPctTotExpHlth</th>\n",
       "      <th>PCptaGovtExpHlthAvgExcRt</th>\n",
       "      <th>GDPPCptaIntDol</th>\n",
       "      <th>AdultLtrcyRate</th>\n",
       "      <th>FemaleLtrcyRate</th>\n",
       "      <th>BurdenOfDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2986</td>\n",
       "      <td>0.10891</td>\n",
       "      <td>0.18812</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.15842</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>4</td>\n",
       "      <td>430</td>\n",
       "      <td>0.35644</td>\n",
       "      <td>0.20792</td>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.58</td>\n",
       "      <td>13306</td>\n",
       "      <td>0.94059</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>49</td>\n",
       "      <td>6158</td>\n",
       "      <td>0.85644</td>\n",
       "      <td>0.78713</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>473</td>\n",
       "      <td>0.79208</td>\n",
       "      <td>0.91089</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>71</td>\n",
       "      <td>4860</td>\n",
       "      <td>0.69307</td>\n",
       "      <td>0.60396</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  FrxnPeaceIn10  ODA4H2OPcptaDol  RenewResm3PcptaYr  \\\n",
       "0  Afghanistan            0.1             0.16               2986   \n",
       "1      Albania            1.0             5.58              13306   \n",
       "2      Algeria            0.0             0.33                473   \n",
       "\n",
       "   SustAccImprWatRur  SustAccImprWatUrb  SustAccImprSanRur  SustAccImprSanUrb  \\\n",
       "0            0.10891            0.18812           0.049505            0.15842   \n",
       "1            0.94059            0.98020           0.801980            0.98020   \n",
       "2            0.79208            0.91089           0.811880            0.98020   \n",
       "\n",
       "   TotHlthExpPctofGDP  GenGovtPctofTotHlthExp  ExtResHlthPctTotExpHlth  \\\n",
       "0               0.065                   0.395                   0.4560   \n",
       "1               0.065                   0.417                   0.0340   \n",
       "2               0.041                   0.808                   0.0005   \n",
       "\n",
       "   PCptaGovtExpHlthAvgExcRt  GDPPCptaIntDol  AdultLtrcyRate  FemaleLtrcyRate  \\\n",
       "0                         4             430         0.35644          0.20792   \n",
       "1                        49            6158         0.85644          0.78713   \n",
       "2                        71            4860         0.69307          0.60396   \n",
       "\n",
       "  BurdenOfDisease  \n",
       "0           awful  \n",
       "1             low  \n",
       "2            high  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"https://serv.cusp.nyu.edu/classes/ML_2016_Spring/ML_2017/Burden of diarrheal illness by country.csv\")\n",
    "print(\"Here are the first three rows:\")\n",
    "data.iloc[0:3,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "NAME: Burden of diarrheal illness by country\n",
    "SIZE: 130 Countries, 16 Variables\n",
    "\n",
    "VARIABLE DESCRIPTIONS:\n",
    "Country: Country name\n",
    "FrxnPeaceIn10: Fraction of the past ten years in which a country has been at peace \n",
    "ODA4H2OPcptaDol: Per Capita Official Developmental Assistance for water projects\n",
    "RenewResm3PcptaYr: Renewable Water Resources in cubic meters per capita per year\n",
    "SustAccImprWatRur: Fraction of rural population with sustainable access to improved water\n",
    "SustAccImprWatUrb: Fraction of urban population with sustainable access to improved water\n",
    "SustAccImprSanRur: Fraction of rural population with sustainable access to improved sanitation\n",
    "SustAccImprSanUrb: Fraction of urban population with sustainable access to improved sanitation\n",
    "TotHlthExpPctofGDP: Fraction of a country's GDP devoted to health spending\n",
    "GenGovtPctofTotHlthExp: The fraction of total health expenditures for a country which is provided by the government\n",
    "ExtResHlthPctTotExpHlth: The fraction of total health expenditures for a country which is comes from sources external to the country\n",
    "PCptaGovtExpHlthAvgExcRt: Per Capita Government Health Expenditures at the average exchange rate\n",
    "GDPPCptaIntDol: Gross Domestic Product per capita in international dollars\n",
    "AdultLtrcyRate: Adult Literacy rate\n",
    "FemaleLtrcyRate: Female Literacy rate\n",
    "\n",
    "BurdenOfDisease: Our target variable for classification.  The burden of disease due to diarrheal illness, categorized into \"low\", \"medium\", \"high\", and \"awful\" quartiles.  For each country, we have estimates of the number of Disability-Adjusted Life Years lost per 1000 persons per year (DALYs) due to diarrheal illness.  Countries with \"low\" burden of disease have up to 2.75345 DALYs; countries with \"medium\" burden of disease have between 2.75345 and 8.2127 DALYs; countries with \"high\" burden of disease have between 8.2127 and 26.699 DALYs; and countries with \"awful\" burden of diease have more than 26.699 DALYs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your goal is to train a decision tree classifier for the attribute “BurdenOfDisease\" using all other variables (except country name) as features using sklearn.tree.DecisionTreeClassifier. http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Please choose a test/train split and choose a hyper-parameter governing model simplicity. For example, the maximum tree depth or maximum number of leaf nodes. Then, fit your decision tree classifier for different values of this parameter and for each such value, record the corresponding AUC score. (10 pts)\n",
    "\n",
    "b) Make a plot of performance vs. simplicity for different values of the hyper-parameter chosen in part a). That is, the x-axis should be hyper-parameter value (e.g. tree depth) and the y-axis should be AUC score. (10 pts)\n",
    "\n",
    "c) Tune the hyper-parameter you choose in part a) by cross-validation using the training data. You can choose to use package from sklearn or write your own code to do cross-validation by spliting the training data into training and validation data. What is the OS accuracy after tuning the hyper-parameter? (10 pts)\n",
    "\n",
    "d) Visualize a simple decision tree (e.g. a “shallow” tree, or a tree with\n",
    "few leaf nodes) classifier and report its performance. You can draw\n",
    "the decision tree by hand or use a graphical representation (e.g.\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html), but make sure it is easy to understand (e.g. the\n",
    "features chosen for each split should be clearly labeled in each\n",
    "internal node, as well as the prediction at each leaf node). (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4, Fit a random forest to the data from question 3 (20 pts)\n",
    "\n",
    "a) Please use the same test/train split from previous question and feel free to tune the hyper-parameters for Random Forest model using training data. The package from sklearn is here: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html.\n",
    "Then please report your out of sample prediction result and compare this model's performance with 2c). (10 pts)\n",
    "\n",
    "b) Write one paragraph comparing the results from those two models (Random Forest vs Decision Tree) in terms of both accuracy and interpretability. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
